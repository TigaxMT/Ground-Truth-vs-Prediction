{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs Vs Cats com Torch\n",
    "\n",
    "Fiz este notebook para aprender PyTorch sendo que eu estou a mudar de Tensorflow para PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "* `zipfile` - Extrair as imagens de treino e testes dos ficheiros ZIP\n",
    "* `time` - Guardar o timestamp quando alguma métrica é guardada em disco\n",
    "* `os` - Útil para navegar nos ficheiros\n",
    "* `random` - Selecionar um número aleatório para a seed\n",
    "* `numpy` - Para baralhar e para matemática em geral\n",
    "* `pandas` - Criar o ficheiro de submissão .csv\n",
    "* `shutil` - Mover imagens\n",
    "* `PIL.Image` - Carregar imagens de validção\n",
    "* `collections` - Criar dicionários aninhados\n",
    "* `tqdm` - Barras de progresso\n",
    "* `torch.utils.data.DataLoader` - Criar conjuntos(batches) de forma fácil\n",
    "* `torch.utils.data.Dataset` - Criar um dataset personalizado com os dados de validação\n",
    "* `torch.utils.data.sampler.SubsetRandomSampler` - Escolher amostras de um sub conjunto de índices\n",
    "* `torchvision.datasets` - Carregar imagens e labels de um diretório raiz\n",
    "* `torchvision.transforms` - Aplicar transformações de uma dado dataset\n",
    "* `torchvision.models` - Carregar modelos pretreinados\n",
    "* `torchvision.utils.makegrid` - Plotar múltiplas imagens\n",
    "* `torch` - Métodos comuns do PyTorch\n",
    "* `torch.nn` - Módulos para construir layers\n",
    "* `torch.nn.functional` - Métodos como funções de ativação\n",
    "* `torch.optim` - Otimizadores\n",
    "* `matplotlib.pyplot` - Plotar\n",
    "* `matplotlib.style` - Trocar o estilo dos plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nós corremos o kernel de novo sem reiniciá-lo, o `metrics.log` mantém-se no disco e vai acumular métricas da última vez que corremos o notebook.\n",
    "\n",
    "Para prevenir isso vamos removê-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm '/kaggle/working/metrics.log'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolher o dispositivo que vai correr o modelo tanto durante o treino como durante a validação e testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "Descomprimir os conjuntos de treino e test que estão no diretório `/kaggle/working/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair os ZIPs\n",
    "with zipfile.ZipFile(\"../input/dogs-vs-cats/train.zip\", \"r\") as unzip:\n",
    "    unzip.extractall(\".\")\n",
    "\n",
    "    \n",
    "with zipfile.ZipFile(\"../input/dogs-vs-cats/test1.zip\", \"r\") as unzip:\n",
    "    unzip.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar outro diretório com 2 pastas dentro (uma para cada classe/label). Se elas já existirem não criaremos novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"my_train/dogs\", exist_ok=True)\n",
    "os.makedirs(\"my_train/cats\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui as imagens de treino são movida para a pasta da classe correta dentro de `my_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"train\"\n",
    "imgs = os.walk(root).__next__()[2]\n",
    "folders = {\n",
    "    \"cat\": \"my_train/cats\",\n",
    "    \"dog\": \"my_train/dogs\"\n",
    "}\n",
    "\n",
    "for img in tqdm(imgs):\n",
    "    label = img.split(\".\")[0]\n",
    "    \n",
    "    old_path = os.path.join(root, img)\n",
    "    new_path = os.path.join(folders[label], img)\n",
    "    \n",
    "    shutil.move(old_path, new_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui as imagens que estão dentro de `my_train` são transformadas e divididas em 2 datasets: `train` and `val` - um para treino e outro para validação.\n",
    "\n",
    "Provavelmente estão a perguntar - \"Porque colocaste esse valores específicos no método Normalize?\" - Quando usamos datasets pré-treinados no ImageNet, estes valores foram estimado por eles (ImageNet) utilizando milhões de imagens. Logo isso dá uma boa estimativa em termo de média e desvio-padrão.\n",
    "\n",
    "\"E porquê 2 arrays com 3 valores cada?\" - O primeiro array é para média e o segundo é para o desvio-padrão. E usamos 3 valores, porque as imagens são normalizadas na dimensão de profundidade (na dimensão dos canais) e nós temos imagens em RGB, logo temos 3 canais (um valor para cada canal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho da imagem\n",
    "IMG_SIZE = 260\n",
    "\n",
    "# Transformações\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(0.5)\n",
    "])\n",
    "\n",
    "# Carregar as imagens e labels\n",
    "dataset = datasets.ImageFolder(root=\"my_train\", transform=data_transforms)\n",
    "\n",
    "# Obter o nome de cada label numérica\n",
    "classes = dataset.classes\n",
    "\n",
    "# 20% do dataset de treino será usado para\n",
    "# validação\n",
    "val_split = 0.2\n",
    "dataset_size = len(dataset)\n",
    "idxs = list(range(dataset_size))\n",
    "\n",
    "# Número de imagens de validação\n",
    "split = int(val_split * dataset_size)\n",
    "\n",
    "# Gerar um seed aleatório e baralhar os índices\n",
    "np.random.seed(random.randint(0, 99999))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "dataset_size = {\n",
    "    \"train\": dataset_size - split,\n",
    "    \"val\": split\n",
    "}\n",
    "\n",
    "# Fazer com que os data sampler selecionem N imagens únicas\n",
    "# de cada dataset\n",
    "train_sampler = SubsetRandomSampler(idxs[:-split])\n",
    "val_sampler = SubsetRandomSampler(idxs[-split:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir o dataset em 2 dataloaders e cada um vai receber um sub conjunto de imagens únicas, divididas em batches (conjuntos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": DataLoader(dataset, batch_size=64, sampler=train_sampler),\n",
    "    \"val\": DataLoader(dataset, batch_size=64, sampler=val_sampler),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas uma simples função para mostra 4 imagens do dataloader de treino.\n",
    "\n",
    "Algumas pessoas não entendem o porquê destas linhas de código:\n",
    "`mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "inp = std * inp + mean\n",
    "inp = np.clip(inp, 0, 1)`\n",
    "\n",
    "Se está a ler desde o início deverá saber que usamos a média e o desvio-padrão para normalizar as imagens, logo as 2 primeiras linhas estão explicadas. Agora o porquê de `inp` ser  igual a `std * inp + mean`.\n",
    "\n",
    "Em estatística temos algo chamado de ***Standard Scores*** ou ***Z-score*** e nós podemos usá-lo para normalizar valores (apenas se soubermos a média e o desvio-padrão da população). A expressão é:\n",
    "$\\frac{X - \\mu}{\\sigma}$, onde $X$ é a nossa imagem, $\\mu$ a média e $\\sigma$ o desvio-padrão.\n",
    "\n",
    "Mais informações acerca do deste assunto, [aqui](https://en.wikipedia.org/wiki/Standard_score)\n",
    "\n",
    "Então as nossas imagens foram normalizadas com essa expressão e devido a isso o matplotlib não plotará as imagens como esperamos, pois os valores dos pixeis estão normalizados. Para \"desnormalizar\" precisamos de reverter a expressão do ***z-score***:\n",
    "$X * \\sigma + \\mu$\n",
    "\n",
    "Como podemos ver todas as operações da expressão foram invertidas e isso reflete-se no seguinte código:\n",
    "`std * inp + mean`\n",
    "\n",
    "Agora, o que é o `clip()` faz? *Clipar* é pegar pegar em todos os valores e traduzi-los (passá-los) para dentro de um certo intervalo que neste caso é um intervalo = [0,1]. Se durante a \"desnormalização\" alguns valores forem < 0 ou > 1, eles serão transformados em valores próximos de 0 (se o valor for < 0) ou em valores próximos de 1 (se o valor for > 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(inp)\n",
    "    \n",
    "    if title != None:\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.pause(0.001)\n",
    "\n",
    "    \n",
    "features, labels = next(iter(dataloaders[\"train\"]))\n",
    "features = features[:4]\n",
    "labels = labels[:4]\n",
    "out = make_grid(features)\n",
    "\n",
    "imshow(out, title=[classes[x] for x in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader para testes\n",
    "Este dataset personalizado pega em todos os nomes dos ficheiros no diretório `test1` e quando iteramos em todos esses ficheiros, o dataset vai ler cada uma das imagens, aplicar transformações (caso as passemos) e retornar a image e o nome dela (que será útil para a criaćão do CSV para submissão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.paths = os.walk(root_dir).__next__()[2]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = os.path.join(self.root_dir, self.paths[idx])\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.transform != None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, self.paths[idx].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criar um dataloarder com o dataset personalizado. As transformações são as mesmas exceto o `RandomFlip` que é excluido, porque as imagens não devem ser transformadas neste dataloader de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(root_dir=\"./test1\", transform=transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, _ = next(iter(test_dataloader))\n",
    "imgs = imgs[:4]\n",
    "out = make_grid(imgs)\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função mais importante, onde o treino e a validação acontecem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs=5, model_name=\"model\", lr_scheduler=None):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\\n\".format(epoch+1, num_epochs))\n",
    "        \n",
    "        for step in dataloaders:\n",
    "            \n",
    "            # Todas as layers com trainning=True\n",
    "            if step == \"train\":\n",
    "                model.train()\n",
    "            \n",
    "            # Todas as layers com trainning=False\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            # Custo\n",
    "            l = 0\n",
    "            # Acurácia\n",
    "            acc = 0\n",
    "            \n",
    "            for X_batch, y_batch in tqdm(dataloaders[step]):\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                # Zerar o gradiente, porque cada batch deve ter o seu próprio gradiente\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "                # Treinar\n",
    "                # Comg gradientes =True em todas as layers\n",
    "                with torch.set_grad_enabled(step == \"train\"):\n",
    "                    preds = model(X_batch)\n",
    "                    \n",
    "                    # o max retorna uma tupla com os valores máximos e os respetivos \n",
    "                    # índices. Eu quero apenas os índices, pois o CrossEntropy\n",
    "                    # retorna um Tensor com todas as probabilidades \"desnormalizadas\"\n",
    "                    # para cada label. O índice da probabilidade mais alta é o label\n",
    "                    # predito\n",
    "                    _, max_idxs = torch.max(preds, dim=1)\n",
    "                    \n",
    "                    \n",
    "                    # Calcular erros\n",
    "                    loss = loss_fn(preds, y_batch)\n",
    "                    \n",
    "                    # Treino a sério abaixo\n",
    "                    if step == \"train\":\n",
    "                        ## regularizador L2 \n",
    "                        #l2_factor = 0.005\n",
    "                        #l2_reg = l2_factor * np.sum([(w**2).sum() for w in model.parameters()])\n",
    "                        #loss = loss + l2_reg\n",
    "                        \n",
    "                        # Backprop + atualização do pesos\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                # Métricas\n",
    "                l += loss.item() * X_batch.size(0)\n",
    "                acc += torch.sum(max_idxs == y_batch.data)\n",
    "                \n",
    "                # Escrever as métricas referentes ao batch atual, em um ficheiro\n",
    "                with open(model_name+\".log\", \"a\") as f:\n",
    "                    f.write(\"{},{},{},{}\\n\".format(\n",
    "                        round(time.time(), 3),\n",
    "                        step,\n",
    "                        torch.sum(max_idxs == y_batch.data).item() / y_batch.size(0),\n",
    "                        loss.item()\n",
    "                    ))\n",
    "                \n",
    "            # Calcular a média das métricas durante cada epoch\n",
    "            epoch_loss = l / dataset_size[step]\n",
    "            epoch_acc = acc.double() / dataset_size[step]\n",
    "            \n",
    "            # Atualizar learning rate\n",
    "            # Podemos alterar o learning rate a cada epoch \n",
    "            # utilizando o learning rate scheduler\n",
    "            if step == \"train\" and lr_scheduler != None:\n",
    "                lr_scheduler.step()\n",
    "            \n",
    "            print(\"{} Acc: {:.3f} - Loss: {:.3f}\".format(step, epoch_acc, epoch_loss))\n",
    "        print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo personalizado\n",
    "Aqui é a minha célula de testes, onde eu tento criar alguns modelos personalizados, mas eles não funcionaram até agora.\n",
    "\n",
    "**Podem passar para a próxima célula, já que este modelo não será usado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 5, stride=(2,2))\n",
    "        self.res_conv1 = None\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=3//2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=3//2)\n",
    "        self.res_conv3 = None\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=3//2)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, padding=3//2)\n",
    "        \n",
    "         \n",
    "        \n",
    "        x = torch.randn(3, IMG_SIZE, IMG_SIZE).view(-1, 3, IMG_SIZE, IMG_SIZE)\n",
    "        self.get_flatten = None\n",
    "        \n",
    "        # Obter o número de parâmetros na última layer de convolução\n",
    "        self.forward_convolutions(x)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.get_flatten, 2)\n",
    "    \n",
    "    def forward_convolutions(self, X):\n",
    "        X = F.relu( self.conv1(X) )\n",
    "        self.res_conv1 = X\n",
    "        \n",
    "        X = F.relu( self.conv2(X) )\n",
    "        X = F.relu( self.conv3(X) )\n",
    "        X = self.res_conv1 + X\n",
    "        self.res_conv3 = X\n",
    "        \n",
    "        X = F.relu( self.conv4(X) )\n",
    "        X = F.relu( self.conv5(X) )\n",
    "        X = self.res_conv3 + X\n",
    "        \n",
    "        \n",
    "        # Se estivermos a tentar obter o número de\n",
    "        # parâmetros na última convolução\n",
    "        if self.get_flatten == None:\n",
    "            self.get_flatten = 1\n",
    "\n",
    "            for sz in X.size()[1:]:\n",
    "                self.get_flatten *= sz\n",
    "        \n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.forward_convolutions(X)\n",
    "        \n",
    "        X = X.view(-1, self.get_flatten)\n",
    "        X = self.dropout(X)\n",
    "        \n",
    "        return self.fc1(X)\n",
    "\n",
    "    \n",
    "    def calc_outputs(self):\n",
    "        # Calcular o tamanho do output\n",
    "        # de cada layer de convolução\n",
    "        \n",
    "        conv_idx = 1\n",
    "        \n",
    "        out_h_prev = out_w_prev = IMG_SIZE\n",
    "        \n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                inp = (out_h_prev, out_w_prev)\n",
    "                out = layer.out_channels\n",
    "                k = layer.kernel_size\n",
    "                s = layer.stride\n",
    "                p = layer.padding\n",
    "\n",
    "                out_h = ( ( inp[0] + (2*p[0]) - k[0] ) // s[0] ) + 1\n",
    "                out_w = ( ( inp[1] + (2*p[1]) - k[1] ) // s[1] ) + 1 \n",
    "                \n",
    "                print(\"Output Convolution Layer {} = ({},{})\".format(\n",
    "                    conv_idx,\n",
    "                    out_h//2, # convoluções são divididas por 2, pois todas elas passam por uma pool layer \n",
    "                    out_w//2 # com uma pool window de tamanho 2x2 e com stride 2x2, o que faz ficar com metade do tamanho\n",
    "                ))\n",
    "                \n",
    "                out_h_prev, out_w_prev = out_h, out_w\n",
    "                \n",
    "                conv_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apenas para testar o output final do nosso feature extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = CNN()\n",
    "\n",
    "#test.calc_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui eu testo diferentes parâmetros para o meu próprio modelo e para o modelo resnet18 pré-treinado.\n",
    "\n",
    "Eu verifiquei que:\n",
    "* Dropout com 50% de probs. de os neurónios serem temporariamente \"mortos\", diminui o custo de validação\n",
    "* Otimizador Adam a começar com um learning rate de 0.001 converge bastante rápido\n",
    "* O learning rate step com um gamma = 5 e apenas mudar a cada 5 epochs, ajuda a aumentar a acurácia e a diminuir o custo do conjunto de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Depois de akguns testes verifiquei que 10 epochs são suficientes para o resnet18\n",
    "model_names = {\n",
    "    #\"model_cnn_3conv,3k,1epoch\": 1,\n",
    "    #\"model_cnn_3conv,3k,3epoch\": 3,\n",
    "    #\"model_resnet18,5epoch\": 5,\n",
    "    \"model_resnet18,10epoch\": 10,\n",
    "}\n",
    "\n",
    "for k,v in model_names.items():\n",
    "    ## Transfer Learning\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    n_features = model.fc.in_features\n",
    "    \n",
    "    # Congelar as layers, exceto a minha nova layer Linear/Dense\n",
    "    for layer in model.parameters():\n",
    "        layer.requires_grad = False\n",
    "    \n",
    "    model.fc = nn.Sequential(collections.OrderedDict([\n",
    "        (\"fc_dropout1\", nn.Dropout(0.5)),\n",
    "        (\"fc_softmax\", nn.Linear(n_features, 2))\n",
    "    ]))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    \n",
    "    ## O meu modelo\n",
    "    #model = CNN().to(device)\n",
    "    \n",
    "    # Função custo\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Otimizador\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    ## Decadência do learning rate por um fator de 5 a cada 5 epochs\n",
    "    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=5)\n",
    "    model = train(model, loss_fn, optimizer, num_epochs=v, \n",
    "                  model_name=k, lr_scheduler=exp_lr_scheduler)\n",
    "    \n",
    "    \n",
    "    ## Quando temos múltiplos model_names é bom eliminar\n",
    "    ## o objeto do modelo, para prevernir o uso de pesos treinados\n",
    "    ## do modelo anterior\n",
    "    #del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizar métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui criamos um grande dicionário para guardar todas as acurácias de treino e teste e custos (aqueles que guardamos em um ficheiro durante o treino/validação)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dict = lambda: collections.defaultdict(nested_dict)\n",
    "\n",
    "models_metrics = nested_dict()\n",
    "\n",
    "for k,v in model_names.items():\n",
    "\n",
    "    train_accs = []\n",
    "    train_losses =[]\n",
    "    val_accs = []\n",
    "    val_losses = []\n",
    "    losses_removed = 0\n",
    "    with open(k+\".log\") as f:\n",
    "        for line in f:\n",
    "            acc = line.split(\",\")[2]\n",
    "            loss = line.split(\",\")[3]\n",
    "            \n",
    "            # The model goes really bad with some batches\n",
    "            # To keep the plot with values between 0 and 1\n",
    "            # I delete all the losses greater than 1\n",
    "            if float(loss) > 1.0:\n",
    "                losses_removed += 1\n",
    "                continue\n",
    "                \n",
    "\n",
    "            if \"train\" in line:\n",
    "                train_accs.append(float(acc))\n",
    "                train_losses.append(float(loss))\n",
    "            else:\n",
    "                val_accs.append(float(acc))\n",
    "                val_losses.append(float(loss))\n",
    "    \n",
    "    models_metrics[k][\"train_accs\"] = train_accs\n",
    "    models_metrics[k][\"train_losses\"] = train_losses\n",
    "    models_metrics[k][\"val_accs\"] = val_accs\n",
    "    models_metrics[k][\"val_losses\"] = val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de suavização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As métricas dos batches podem ser muito instáveis, logo eu tentei implementar 2 métodos para suaviazar as linhas plotadas.\n",
    "A **Hanning Window** é uma função usada no processamento de sinais para suavizar valores e é definida como:\n",
    "$\\frac{1}{2} - \\frac{1}{2}cos(\\frac{2\\pi n}{M-1})$, onsde $n$ é o valor atual e $M$ é o número total de valores.\n",
    "\n",
    "Se multiplicarmos o resultado pelo valor atual, ele deve ser suavizado (numéricamente ele fica mais pequeno, mas visualmente a diferença é quase imperceptível).\n",
    "\n",
    "A **Moving Average** é basicamente a média que usa todos os valores calculados previamente. Então quando chegamos ao último valor, o primeiro valor não tem quase impacto na média. Eu tentei implementar a versão usada no Tensorboard, mas não funcionou (provavelmente eu preciso colocar os devidos expoentes para cada valor, para assim os valores mais próximos do atual terem mais impacto que os mais antigos). Acabei apenas por usar a hanning window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hanning_window(metric):\n",
    "    for i in range(len(metric)):\n",
    "        n = metric[i]\n",
    "        h_metric = 0.5 - 0.5 * np.cos( (2*np.pi*n) / (len(metric)-1) )\n",
    "        metric[i] *= n\n",
    "\n",
    "    return metric\n",
    "\n",
    "\n",
    "def moving_average(metric, w):\n",
    "    \n",
    "    last_smooth = metric[0]\n",
    "    smoothed_metric = []\n",
    "    \n",
    "    for i, p in enumerate(metric):\n",
    "        if i == 0:\n",
    "            smooth = p\n",
    "        else:\n",
    "            smooth = last_smooth * w + (1 - w) + p \n",
    "        \n",
    "        smoothed_metric.append( smooth )\n",
    "        last_smooth = smooth\n",
    "        \n",
    "    return smoothed_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular cada métrica e transformar as métricas guardar utilizando a Hanning Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in model_names.items():\n",
    "    \n",
    "    mean_train_acc, mean_train_loss = np.mean(models_metrics[k][\"train_accs\"]), np.mean(models_metrics[k][\"train_losses\"])\n",
    "    mean_val_acc, mean_val_loss = np.mean(models_metrics[k][\"val_accs\"]), np.mean(models_metrics[k][\"val_losses\"])\n",
    "    \n",
    "    models_metrics[k][\"mean_train_acc\"] = mean_train_acc\n",
    "    models_metrics[k][\"mean_train_loss\"] = mean_train_loss\n",
    "    models_metrics[k][\"mean_val_acc\"] = mean_val_acc\n",
    "    models_metrics[k][\"mean_val_loss\"] = mean_val_loss\n",
    "\n",
    "    \n",
    "        \n",
    "    models_metrics[k][\"train_accs\"] = hanning_window(models_metrics[k][\"train_accs\"])\n",
    "    models_metrics[k][\"train_losses\"] = hanning_window(models_metrics[k][\"train_losses\"])\n",
    "    models_metrics[k][\"val_accs\"] = hanning_window(models_metrics[k][\"val_accs\"])\n",
    "    models_metrics[k][\"val_losses\"] = hanning_window(models_metrics[k][\"val_losses\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora posso usar o dicionário grande para plotar a acurácina e o custo de treino assim como as de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"ggplot\")\n",
    "\n",
    "for k,v in model_names.items():\n",
    "    f, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "    ax1.set_title(k)\n",
    "    \n",
    "    ax1.plot(np.arange(len(models_metrics[k][\"train_accs\"])), models_metrics[k][\"train_accs\"], label=\"Acc - Mean: {:.2f}\".format(models_metrics[k][\"mean_train_acc\"]))\n",
    "    ax1.plot(np.arange(len(models_metrics[k][\"train_losses\"])), models_metrics[k][\"train_losses\"], label=\"Loss - Mean: {:.2f}\".format(models_metrics[k][\"mean_train_loss\"]))\n",
    "\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(np.arange(len(models_metrics[k][\"val_accs\"])), models_metrics[k][\"val_accs\"], label=\"Val Acc - Mean: {:.2f}\".format(models_metrics[k][\"mean_val_acc\"]))\n",
    "    ax2.plot(np.arange(len(models_metrics[k][\"val_losses\"])), models_metrics[k][\"val_losses\"], label=\"Val Loss - Mean: {:.2f}\".format(models_metrics[k][\"mean_val_loss\"]))\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Guardar o plot como uma imagem para poder analisar e comparar\n",
    "    # com outros testes que fiz\n",
    "    plt.savefig(k+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui eu apenas usei o dataloader de test para prever o label/classe de cada imagem. Coloquei o nome da imagem como key e o label predito como valor no dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_dict = dict()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch,names in tqdm(test_dataloader):\n",
    "        X_batch = X_batch.to(device)\n",
    "        \n",
    "        preds = model(X_batch)\n",
    "        \n",
    "        _, ys = torch.max(preds, dim=1)\n",
    "        \n",
    "        for y, name in zip(ys, names):\n",
    "            pred_dict[int(name)] = y.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criei um DataFrame com o dicionário e com a estrutura de submissão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(pred_dict.items(), columns=[\"id\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar o DataFrane com um ficheiro .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
